{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness Metrics on words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset\n",
    "# importing the dataset\n",
    "first_data = pd.read_csv('../data/fake_and_real_data.csv')\n",
    "first_data.head()\n",
    "second_data = pd.read_csv('../data/WELFake_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "\n",
    "second_data.isnull().sum()\n",
    "\n",
    "# Dropping the missing values\n",
    "second_data = second_data.dropna()\n",
    "# Checking for duplicates\n",
    "\n",
    "second_data.duplicated().sum()\n",
    "\n",
    "# Drop unnamed column\n",
    "second_data.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatinating title and text\n",
    "second_data['text'] = second_data['title'] + ' ' + second_data['text']\n",
    "# Dropping the title column\n",
    "second_data = second_data.drop(['title'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                    Text label  label_t\n",
       "0      Top Trump Surrogate BRUTALLY Stabs Him In The...  Fake        0\n",
       "1     U.S. conservative leader optimistic of common ...  Real        0\n",
       "2     Trump proposes U.S. tax overhaul, stirs concer...  Real        0\n",
       "3      Court Forces Ohio To Allow Millions Of Illega...  Fake        0\n",
       "4     Democrats say Trump agrees to work on immigrat...  Real        0\n",
       "...                                                 ...   ...      ...\n",
       "9895   Wikileaks Admits To Screwing Up IMMENSELY Wit...  Fake        0\n",
       "9896  Trump consults Republican senators on Fed chie...  Real        0\n",
       "9897  Trump lawyers say judge lacks jurisdiction for...  Real        0\n",
       "9898   WATCH: Right-Wing Pastor Falsely Credits Trum...  Fake        0\n",
       "9899   Sean Spicer HILARIOUSLY Branded As Chickensh*...  Fake        0\n",
       "\n",
       "[9865 rows x 3 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_data.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "first_data['label_t'] = 0\n",
    "\n",
    "\n",
    "first_data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Trump Surrogate BRUTALLY Stabs Him In The...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. conservative leader optimistic of common ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump proposes U.S. tax overhaul, stirs concer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Court Forces Ohio To Allow Millions Of Illega...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrats say Trump agrees to work on immigrat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0   Top Trump Surrogate BRUTALLY Stabs Him In The...      0\n",
       "1  U.S. conservative leader optimistic of common ...      1\n",
       "2  Trump proposes U.S. tax overhaul, stirs concer...      1\n",
       "3   Court Forces Ohio To Allow Millions Of Illega...      0\n",
       "4  Democrats say Trump agrees to work on immigrat...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing the data\n",
    "first_data['label_t'] = (first_data['label'] != 'Fake').astype(int)\n",
    "first_data = first_data.drop(['label'], axis=1)\n",
    "first_data = first_data.rename(columns={'label_t': 'label'})\n",
    "first_data = first_data.rename(columns={'Text': 'text'})\n",
    "first_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the unnecessary columns\n",
    "first_data.head()\n",
    "# converting the text to lowercase\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'[^\\w\\s\\']', ' ', text)\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    return text.strip().lower()\n",
    "\n",
    "first_data['text'] = first_data['text'].apply(preprocess)\n",
    "second_data['text'] = second_data['text'].apply(preprocess)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>top trump surrogate brutally stabs him in the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u s conservative leader optimistic of common g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trump proposes u s tax overhaul stirs concerns...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>court forces ohio to allow millions of illegal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>democrats say trump agrees to work on immigrat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  top trump surrogate brutally stabs him in the ...      0\n",
       "1  u s conservative leader optimistic of common g...      1\n",
       "2  trump proposes u s tax overhaul stirs concerns...      1\n",
       "3  court forces ohio to allow millions of illegal...      0\n",
       "4  democrats say trump agrees to work on immigrat...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_data.head()\n",
    "second_data.head()\n",
    "\n",
    "concat_data = pd.concat([first_data, second_data], axis=0)\n",
    "concat_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is trump inclouded \n",
    "\n",
    "concat_data['does_contain_trump'] = concat_data['text'].apply(lambda x: 'trump' in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>does_contain_trump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>top trump surrogate brutally stabs him in the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u s conservative leader optimistic of common g...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trump proposes u s tax overhaul stirs concerns...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>court forces ohio to allow millions of illegal...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>democrats say trump agrees to work on immigrat...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  top trump surrogate brutally stabs him in the ...      0   \n",
       "1  u s conservative leader optimistic of common g...      1   \n",
       "2  trump proposes u s tax overhaul stirs concerns...      1   \n",
       "3  court forces ohio to allow millions of illegal...      0   \n",
       "4  democrats say trump agrees to work on immigrat...      1   \n",
       "\n",
       "   does_contain_trump  \n",
       "0                True  \n",
       "1                True  \n",
       "2                True  \n",
       "3                True  \n",
       "4                True  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "does_contain_trump\n",
       "True     41635\n",
       "False    39767\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_data['does_contain_trump'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simply import it from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = concat_data \n",
    "\n",
    "# Separating features from target feature\n",
    "features = dataset.columns.tolist()\n",
    "features.remove('label')\n",
    "target = 'label'\n",
    "X = dataset[features]\n",
    "y = dataset[target]\n",
    "\n",
    "# Define four sets and apply the function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2, # 0.2 indicates a test set size of 20%\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.7105214667403722\n",
      "Decision Tree Recall: 0.7023909647963474\n",
      "Decision Tree F1 Score: 0.712709539774459\n"
     ]
    }
   ],
   "source": [
    "## applying fairness tests\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "# Import the classifier and the metrics from sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "vect = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "xv_train = vect.fit_transform(X_train['text'])\n",
    "xv_test = vect.transform(X_test['text'])\n",
    "\n",
    "\n",
    "# The fit function will do the trick\n",
    "dt_clf.fit(xv_train, y_train)\n",
    "\n",
    "# After the training phase, the model will be tested by predicting the values on the test set\n",
    "dt_predictions = dt_clf.predict(xv_test)\n",
    "\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "dt_recall = recall_score(y_test, dt_predictions)\n",
    "dt_f1_score = f1_score(y_test, dt_predictions)\n",
    "print(f\"Decision Tree Accuracy: {dt_accuracy}\")\n",
    "print(f\"Decision Tree Recall: {dt_recall}\")\n",
    "print(f\"Decision Tree F1 Score: {dt_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'csr_matrix' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m xv_test\u001b[38;5;241m.\u001b[39mhead\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'csr_matrix' object has no attribute 'head'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m trump_features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoes_contain_trump\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m dataset \u001b[38;5;241m=\u001b[39m xv_test\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[0;32m---> 11\u001b[0m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_test  \u001b[38;5;66;03m# and join the target feature with the others\u001b[39;00m\n\u001b[1;32m     13\u001b[0m predictions \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# we do the same task\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# but this time the target feature is made by the predictions of our model\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "\n",
    "# We want to check the fairness level regarding the protected attribute \"sex\"\n",
    "trump_features = ['does_contain_trump']\n",
    "\n",
    "\n",
    "dataset = xv_test.toarray()\n",
    "dataset['label'] = y_test  # and join the target feature with the others\n",
    "\n",
    "predictions = dataset.copy(deep=True)  # we do the same task\n",
    "# but this time the target feature is made by the predictions of our model\n",
    "predictions['label'] = dt_predictions\n",
    "\n",
    "# In this way, we have two datasets. One (dataset) is the original test set containing the original values of features,\n",
    "# the other (predictions) contains the original values except for the target one, that is now made of model's predictions\n",
    "\n",
    "# These will be used by AIF to compare the classifications of the model with the original values to\n",
    "# understand if the model's answers create favouritism toward the privileged attribute\n",
    "\n",
    "\n",
    "# This is the object made of the original dataset\n",
    "aif_sex_dataset = BinaryLabelDataset(  # Base class for all structured datasets with binary labels.\n",
    "    df=dataset,\n",
    "    # This means that a prediction is biased toward the privileged attribute if its value is 1 (True)\n",
    "    favorable_label=1,\n",
    "    unfavorable_label=0,\n",
    "    label_names=[target],\n",
    "    protected_attribute_names=trump_features,\n",
    "    # here we tell AIF that we want to check for predictions\n",
    "    privileged_protected_attributes=['does_contain_trump'],\n",
    "    # that somehow privilege the attribute \"sex_Male\"\n",
    ")\n",
    "\n",
    "# We do the same thing but with the predictions dataset\n",
    "aif_sex_pred = BinaryLabelDataset(\n",
    "    df=predictions,\n",
    "    favorable_label=1,\n",
    "    unfavorable_label=0,\n",
    "    label_names=[target],\n",
    "    protected_attribute_names=trump_features,\n",
    "    privileged_protected_attributes=['does_contain_trump'],\n",
    ")\n",
    "\n",
    "trump_privileged_group = [{'does_contain_trump': 1}]\n",
    "trump_unprivileged_group = [{'does_contain_trump': 0}]    \n",
    "\n",
    "# We provide the ClassificationMetric object with all the information needed:\n",
    "# aif_sex_dataset - The original test set\n",
    "# aif_sex_pred - A dataset containing the predictions of the model\n",
    "# sex_privileged_group - The privileged group\n",
    "# sex_unprivileged_group - The unprivileged group\n",
    "fairness_metrics = ClassificationMetric(dataset=aif_sex_dataset,\n",
    "                                        classified_dataset=aif_sex_pred,\n",
    "                                        unprivileged_groups=trump_unprivileged_group,\n",
    "                                        privileged_groups=trump_unprivileged_group)\n",
    "\n",
    "# Values less than 0 indicate that privileged group has higher\n",
    "# proportion of predicted positive outcomes than unprivileged group.\n",
    "# Value higher than 0 indicates that unprivileged group has higher proportion\n",
    "# of predicted positive outcomes than privileged group.\n",
    "SPD = round(fairness_metrics.statistical_parity_difference(), 3)\n",
    "\n",
    "# Measures the deviation from the equality of opportunity, which means that the same\n",
    "# proportion of each population receives the favorable outcome. This measure must be equal to 0 to be fair.\n",
    "EOD = round(fairness_metrics.equal_opportunity_difference(), 3)\n",
    "\n",
    "# Average of difference in False Positive Rate and True Positive Rate for unprivileged and privileged groups\n",
    "# A value of 0 indicates equality of odds, which means that samples in both the privileged and unprivileged\n",
    "# groups have the same probability of being classified positively.\n",
    "AOD = round(fairness_metrics.average_odds_difference(), 3)\n",
    "\n",
    "print(f\"Statistical Parity Difference (SPD): {SPD}\")\n",
    "print(f\"Equal Opportunity Difference (EOD): {EOD}\")\n",
    "print(f\"Average Odds Difference: {AOD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
